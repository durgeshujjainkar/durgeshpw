{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you generate a random sentence using probabilistic modeling (Markov Chain)?\n",
    "\n",
    "import random\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"The cat is on the mat\"\n",
    "\n",
    "# Split the sentence into words\n",
    "words = sentence.split()\n",
    "\n",
    "# Build a Markov chain model (bigram model)\n",
    "markov_chain = {}\n",
    "for i in range(len(words) - 1):\n",
    "    if words[i] not in markov_chain:\n",
    "        markov_chain[words[i]] = []\n",
    "    markov_chain[words[i]].append(words[i + 1])\n",
    "\n",
    "# Function to generate a random sentence\n",
    "def generate_sentence(start_word, length=6):\n",
    "    current_word = start_word\n",
    "    sentence = [current_word]\n",
    "    for _ in range(length - 1):\n",
    "        next_word = random.choice(markov_chain.get(current_word, [\".\"]))  # Default to \".\" if no next word\n",
    "        sentence.append(next_word)\n",
    "        current_word = next_word\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Generate a random sentence starting with \"The\"\n",
    "random_sentence = generate_sentence(\"The\")\n",
    "print(random_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you build a simple Autoencoder model using Keras to learn a compressed representation of a given sentence?\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset: Simple sentences as input\n",
    "sentences = [\"I love programming\", \"Data science is fun\", \"Machine learning is exciting\"]\n",
    "# Encode sentences as simple integer representations (just for demonstration)\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # Dummy integer data\n",
    "\n",
    "# Define Autoencoder architecture\n",
    "input_dim = data.shape[1]\n",
    "encoding_dim = 2  # Compressed representation\n",
    "\n",
    "# Define layers\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Create Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train Autoencoder\n",
    "autoencoder.fit(data, data, epochs=100, batch_size=2)\n",
    "\n",
    "# Encoder part to get compressed representation\n",
    "encoder = Model(input_layer, encoded)\n",
    "compressed_representation = encoder.predict(data)\n",
    "print(compressed_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you use the Hugging Face transformers library to fine-tune a pre-trained GPT-2 model on custom text data and generate text?\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load a pre-trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load custom dataset\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": \"path_to_your_text_file.txt\"})\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "\n",
    "# Fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Generate text after fine-tuning\n",
    "input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you implement a text generation model using a simple Recurrent Neural Network (RNN) in Keras?\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding, LSTM\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset (dummy sentences for demonstration)\n",
    "sentences = [\"I love machine learning\", \"Deep learning is amazing\", \"RNNs are cool\"]\n",
    "# Convert sentences to integer tokens (for simplicity)\n",
    "words = set(\" \".join(sentences).split())\n",
    "word_to_int = {word: i for i, word in enumerate(words)}\n",
    "int_sentences = [[word_to_int[word] for word in sentence.split()] for sentence in sentences]\n",
    "\n",
    "# Prepare training data\n",
    "X = np.array([sentence[:-1] for sentence in int_sentences])\n",
    "y = np.array([sentence[1:] for sentence in int_sentences])\n",
    "\n",
    "# Define RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_to_int), output_dim=10, input_length=X.shape[1]))\n",
    "model.add(SimpleRNN(50, return_sequences=True))\n",
    "model.add(Dense(len(word_to_int), activation=\"softmax\"))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.fit(X, y, epochs=100)\n",
    "\n",
    "# Generate text\n",
    "start_word = \"I\"\n",
    "start_token = word_to_int[start_word]\n",
    "generated = [start_token]\n",
    "\n",
    "for _ in range(5):  # Generate 5 words\n",
    "    input_seq = np.array([generated])\n",
    "    prediction = model.predict(input_seq)\n",
    "    next_word = np.argmax(prediction[0, -1])\n",
    "    generated.append(next_word)\n",
    "\n",
    "generated_sentence = \" \".join([list(word_to_int.keys())[list(word_to_int.values()).index(token)] for token in generated])\n",
    "print(generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you write a program to generate a sequence of text using an LSTM-based model in TensorFlow, trained on custom data of sentences?\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Example sentences (custom data)\n",
    "sentences = [\"I love artificial intelligence\", \"Deep learning is amazing\", \"LSTMs are powerful\"]\n",
    "\n",
    "# Preprocess sentences\n",
    "words = set(\" \".join(sentences).split())\n",
    "word_to_int = {word: i for i, word in enumerate(words)}\n",
    "int_sentences = [[word_to_int[word] for word in sentence.split()] for sentence in sentences]\n",
    "\n",
    "# Prepare data\n",
    "X = np.array([sentence[:-1] for sentence in int_sentences])\n",
    "y = np.array([sentence[1:] for sentence in int_sentences])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_to_int), 10),\n",
    "    tf.keras.layers.LSTM(50),\n",
    "    tf.keras.layers.Dense(len(word_to_int), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(X, y, epochs=100)\n",
    "\n",
    "# Generate text\n",
    "start_word = \"I\"\n",
    "start_token = word_to_int[start_word]\n",
    "generated = [start_token]\n",
    "\n",
    "for _ in range(5):  # Generate 5 words\n",
    "    input_seq = np.array([generated])\n",
    "    prediction = model.predict(input_seq)\n",
    "    next_word = np.argmax(prediction[0, -1])\n",
    "    generated.append(next_word)\n",
    "\n",
    "generated_sentence = \" \".join([list(word_to_int.keys())[list(word_to_int.values()).index(token)] for token in generated])\n",
    "print(generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you build a program that uses GPT-2 from Hugging Face to generate a story based on a custom prompt?\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Prompt for story generation\n",
    "prompt = \"Once upon a time, in a distant kingdom,\"\n",
    "\n",
    "# Tokenize the prompt\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the story\n",
    "output = model.generate(input_ids, max_length=200)\n",
    "generated_story = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you implement a simple text generation model using a GRU-based architecture in Keras?\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Embedding\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset (dummy sentences for demonstration)\n",
    "sentences = [\"I love deep learning\", \"GRUs are interesting\", \"Text generation is cool\"]\n",
    "# Convert sentences to integer tokens (for simplicity)\n",
    "words = set(\" \".join(sentences).split())\n",
    "word_to_int = {word: i for i, word in enumerate(words)}\n",
    "int_sentences = [[word_to_int[word] for word in sentence.split()] for sentence in sentences]\n",
    "\n",
    "# Prepare training data\n",
    "X = np.array([sentence[:-1] for sentence in int_sentences])\n",
    "y = np.array([sentence[1:] for sentence in int_sentences])\n",
    "\n",
    "# Define GRU model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_to_int), output_dim=10, input_length=X.shape[1]))\n",
    "model.add(GRU(50, return_sequences=True))\n",
    "model.add(Dense(len(word_to_int), activation=\"softmax\"))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.fit(X, y, epochs=100)\n",
    "\n",
    "# Generate text\n",
    "start_word = \"I\"\n",
    "start_token = word_to_int[start_word]\n",
    "generated = [start_token]\n",
    "\n",
    "for _ in range(5):  # Generate 5 words\n",
    "    input_seq = np.array([generated])\n",
    "    prediction = model.predict(input_seq)\n",
    "    next_word = np.argmax(prediction[0, -1])\n",
    "    generated.append(next_word)\n",
    "\n",
    "generated_sentence = \" \".join([list(word_to_int.keys())[list(word_to_int.values()).index(token)] for token in generated])\n",
    "print(generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you write a program to generate a sequence of text using an LSTM-based model in TensorFlow, trained on custom data of sentences?\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Example sentences (custom data)\n",
    "sentences = [\"I love artificial intelligence\", \"Deep learning is amazing\", \"LSTMs are powerful\"]\n",
    "\n",
    "# Preprocess sentences\n",
    "words = set(\" \".join(sentences).split())\n",
    "word_to_int = {word: i for i, word in enumerate(words)}\n",
    "int_sentences = [[word_to_int[word] for word in sentence.split()] for sentence in sentences]\n",
    "\n",
    "# Prepare data\n",
    "X = np.array([sentence[:-1] for sentence in int_sentences])\n",
    "y = np.array([sentence[1:] for sentence in int_sentences])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_to_int), 10),\n",
    "    tf.keras.layers.LSTM(50),\n",
    "    tf.keras.layers.Dense(len(word_to_int), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(X, y, epochs=100)\n",
    "\n",
    "# Generate text\n",
    "start_word = \"I\"\n",
    "start_token = word_to_int[start_word]\n",
    "generated = [start_token]\n",
    "\n",
    "for _ in range(5):  # Generate 5 words\n",
    "    input_seq = np.array([generated])\n",
    "    prediction = model.predict(input_seq)\n",
    "    next_word = np.argmax(prediction[0, -1])\n",
    "    generated.append(next_word)\n",
    "\n",
    "generated_sentence = \" \".join([list(word_to_int.keys())[list(word_to_int.values()).index(token)] for token in generated])\n",
    "print(generated_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
